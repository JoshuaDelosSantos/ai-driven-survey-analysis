# LLM Conversational Intelligence Integration - Planning Phase

**Objective**: Plan hybrid LLM + template approach for conversational intelligence

## Executive Summary

This planning document outlines the integration of Gemini LLM capabilities into the existing RAG system's conversational intelligence layer. The approach adopts a conservative hybrid strategy that maintains existing template-based responses while adding LLM capabilities for complex, novel, and schema-related queries.

**Key Decisions:**
- **LLM Provider**: Google Gemini (already integrated for text-to-SQL)
- **Strategy**: Conservative hybrid approach with template-first routing
- **Australian Context**: Neutral Australian English spelling and expressions
- **Fallback**: Templates serve as backup for LLM failures
- **Schema**: Cached schema info with pre-computed rich descriptions
- **Success Metrics**: Log-based feedback analysis and performance monitoring

**Technical Scope:**
- Enhance query classification with LLM capabilities
- Implement intelligent routing between template and LLM handlers
- Create schema intelligence layer with examples from `data-dictionary.json`
- Build comprehensive testing and monitoring framework
- Establish documentation standards for all new components

**Timeline**: 4-phase implementation

## Decisions Made

### 1. LLM Integration Scope
- **Primary**: Gemini for conversational responses
- **Secondary**: Gemini for enhanced query classification when current tools insufficient
- **Architecture**: Easily maintainable and upgradeable layer-based approach

### 2. Australian Context Strategy
- **Approach**: Evolve to neutral Australian English
- **Implementation**: Spelling corrections in post-processing
- **Personality**: Professional and helpful, less colloquial than current templates

### 3. Fallback & Reliability
- **Primary Fallback**: Templates when Gemini fails
- **Error Handling**: Graceful degradation with logging
- **Uptime Target**: 99.9% effective response rate

### 4. Success Metrics & Feedback
- **Primary**: Log-based feedback analysis
- **Secondary**: Performance monitoring (latency, cost, accuracy)
- **Process**: Regular log review and system refinement

### 5. Schema Integration
- **Source**: Enhanced context from `src/csv/data-dictionary.json`
- **Strategy**: Cached schema with pre-computed rich descriptions
- **Examples**: Include sample queries and expected responses

### 6. Privacy & Compliance Strategy ✅
- **Framework**: Follow Australian Privacy Principles (APP) as defined in `data-governance.md`
- **PII Protection**: Extend existing multi-layer PII detection to LLM interactions
- **Data Sovereignty**: Schema-only transmission to Gemini (no personal data)
- **Audit Trail**: Enhanced logging with privacy-safe conversational query tracking
- **Incident Response**: Integrate with existing privacy incident response framework

## Enhanced Requirements

### 1. Example-Driven Development
- All new files must include comprehensive example cases
- Real-world usage scenarios for testing and validation
- Sample inputs/outputs for each component

### 2. Documentation Strategy
- Create `README.md` in all new directories
- Update existing `README.md` files in modified directories
- Maintain consistent documentation standards across the project

### 3. LLM Context Requirements
- Include relevant imports and dependencies
- Reference schema location (`src/csv/data-dictionary.json`)
- Provide clear integration points with existing codebase
- Schema relationship understanding and examples

### 4. Privacy & Compliance Requirements (per `data-governance.md`)
- **Multi-layer PII Protection**: Extend existing PII detection to conversational queries
- **Schema-Only Transmission**: Only send database schema descriptions to Gemini
- **Audit Compliance**: Privacy-safe logging of conversational interactions
- **Australian Privacy Principles**: Full APP compliance for LLM integration
- **Cross-border Controls**: Ensure no personal data transmitted to external LLM APIs

### 1. LLM Choice and Infrastructure
- **Which LLM provider/model are you considering?**
  - OpenAI GPT-4/4o (API-based)
  - Azure OpenAI (enterprise)
  - Local models (Ollama, etc.)
  - Claude/Anthropic
  
- **Infrastructure constraints?**
  - Budget for API calls
  - Latency requirements
  - Privacy/data residency needs (Australian data - see `data-governance.md`)
  - Integration with existing Docker setup

### 2. Schema Integration Strategy
- **How dynamic is your data schema?**
  - Does it change frequently?
  - Are new tables/columns added regularly?
  - Do we need real-time schema awareness?

- **Schema complexity level?**
  - How detailed should LLM schema knowledge be?
  - Just table names and purposes, or full column details?
  - Should it understand relationships between tables?

### 3. Hybrid Routing Logic
- **Performance vs. Intelligence trade-off?**
  - What's acceptable latency for conversational responses?
  - Should we optimize for speed or response quality?
  - How important is cost control?

- **Fallback strategy?**
  - What happens if LLM is unavailable?
  - Should templates be the fallback for LLM failures?
  - How do we handle partial failures?

### 4. Australian Context Requirements
- **How important is the Australian tone/context?**
  - Critical for user acceptance?
  - Nice-to-have vs. essential requirement?
  - Specific Australian expressions that must be preserved?

- **Compliance considerations?**
  - Any specific Australian government guidelines?
  - Privacy requirements for LLM usage?
  - Data sovereignty concerns?

### 5. Learning and Feedback Integration
- **How should we leverage your existing pattern learning?**
  - Use learning data to improve LLM prompts?
  - Feed LLM performance back into routing decisions?
  - Maintain both systems' learning capabilities?

- **Success metrics?**
  - How do we measure LLM response quality?
  - User satisfaction tracking?
  - Response time vs. quality trade-offs?

## Refined Hybrid Architecture Plan

### Phase 1: Foundation Layer (1-2 weeks)
**Goal**: Add Gemini LLM capability alongside existing template system

**New Components:**
1. **LLM Service Layer** (`src/rag/core/llm/`)
   ```
   src/rag/core/llm/
   ├── README.md                    # LLM integration documentation
   ├── __init__.py
   ├── gemini_client.py            # Gemini API wrapper with examples
   ├── schema_provider.py          # Schema context from data-dictionary.json
   ├── prompt_templates.py         # System prompts for conversational queries
   ├── response_processor.py       # Australian English post-processing
   └── privacy/
       ├── __init__.py
       ├── llm_pii_detector.py     # LLM-specific PII protection (extends existing)
       └── cross_border_validator.py # Schema-only transmission validation
   ```
   - Gemini client wrapper with error handling and fallbacks
   - Schema context provider using `src/csv/data-dictionary.json`
   - **Privacy Integration**: Extend existing PII detection from `src/rag/core/privacy/`
   - **Cross-border Compliance**: Schema-only transmission validation per `data-governance.md`
   - Prompt templates for Australian English conversational queries
   - Response post-processing for spelling and tone consistency

2. **Enhanced Query Classifier** (update `src/rag/core/routing/query_classifier.py`)
   - Add LLM-enhanced classification capabilities
   - **Privacy Compliance**: PII scanning before LLM classification processing
   - Routing logic: template vs. LLM vs. hybrid decisions
   - Confidence thresholds and performance monitoring hooks
   - Fallback to existing classification when LLM unavailable

3. **Hybrid Conversational Handler** (update `src/rag/core/conversational/`)
   ```
   src/rag/core/conversational/
   ├── README.md                    # Updated with hybrid approach
   ├── handler.py                   # Original template handler (preserved)
   ├── hybrid_handler.py           # New unified interface with examples
   ├── llm_handler.py              # Gemini-based conversational handler
   ├── router.py                   # Intelligence routing between handlers
   └── privacy_validator.py        # Conversational query PII validation
   ```
   - Unified interface maintaining current API compatibility
   - **Privacy Integration**: Conversational query PII validation before LLM processing
   - Intelligent routing between template and LLM handlers
   - Response consistency and quality assurance

**Documentation Updates:**
- Update `src/rag/core/README.md` to include LLM integration
- Create `src/rag/core/llm/README.md` with architecture and examples
- Update `src/rag/core/conversational/README.md` with hybrid approach
- **Privacy Documentation**: Reference `data-governance.md` compliance requirements
- Document cross-border data transmission controls for LLM usage

### Phase 2: Schema Intelligence (1 week)
**Goal**: Make Gemini schema-aware using existing data dictionary

**Components:**
1. **Enhanced Schema Provider** (extend `src/rag/core/llm/schema_provider.py`)
   - Parse and enrich `src/csv/data-dictionary.json`
   - **Privacy Compliance**: Schema-only context generation (no personal data)
   - Generate context-relevant schema summaries
   - Include example queries and expected data relationships
   - Cache schema intelligence with manual refresh capability

2. **Prompt Engineering Framework** (`src/rag/core/llm/prompts/`)
   ```
   src/rag/core/llm/prompts/
   ├── README.md                    # Prompt engineering guidelines
   ├── system_prompts.py           # Core system prompts with examples
   ├── schema_prompts.py           # Schema-aware prompt templates
   ├── australian_context.py       # Australian English guidelines
   └── privacy_prompts.py          # Privacy-safe prompt templates
   ```
   - System prompts for neutral Australian English
   - **Privacy Integration**: Privacy-safe prompt templates per `data-governance.md`
   - Schema injection strategies with data dictionary context
   - Response formatting guidelines and examples

3. **Testing & Validation Framework** (`src/rag/tests/llm/`)
   ```
   src/rag/tests/llm/
   ├── README.md                    # Testing approach and examples
   ├── test_gemini_integration.py  # Gemini client testing
   ├── test_hybrid_routing.py      # Routing logic validation
   ├── test_australian_context.py  # Language and tone testing
   ├── test_schema_awareness.py    # Schema accuracy validation
   ├── test_privacy_compliance.py  # Privacy control testing per data-governance.md
   └── test_cross_border_controls.py # Schema-only transmission validation
   ```
   - Compare template vs. LLM responses with example cases
   - Schema accuracy testing using data dictionary
   - Australian English validation and consistency checks
   - **Privacy Testing**: PII detection and cross-border compliance validation

**Documentation Updates:**
- Create comprehensive prompt engineering documentation
- Update testing documentation with LLM-specific test cases
- **Privacy Documentation**: Document privacy control testing approach
- Reference `data-governance.md` compliance validation requirements

### Phase 3: Intelligent Routing (1 week)
**Goal**: Optimize routing decisions between template and LLM handlers

**Components:**
1. **Smart Router Enhancement** (`src/rag/core/conversational/router.py`)
   - Conservative routing: template-first with clear LLM triggers
   - Performance metrics integration and monitoring
   - A/B testing framework for gradual LLM adoption
   - Example routing scenarios and decision logic

2. **Learning Integration** (extend existing pattern learning)
   - Feed existing pattern learning data into LLM routing decisions
   - Cross-system feedback loops between template and LLM performance
   - Log-based feedback analysis and system optimization
   - Example learning scenarios and improvement cases

3. **Monitoring & Analytics** (`src/rag/core/llm/monitoring/`)
   ```
   src/rag/core/llm/monitoring/
   ├── README.md                    # Monitoring strategy and examples
   ├── performance_tracker.py      # Latency and cost monitoring
   ├── quality_assessor.py         # Response quality metrics
   ├── log_analyzer.py            # Log-based feedback analysis
   ├── privacy_monitor.py         # Privacy compliance monitoring
   └── compliance_reporter.py     # APP compliance reporting integration
   ```
   - Response quality metrics with example assessments
   - Performance tracking (latency, cost, accuracy)
   - Log-based feedback analysis for continuous improvement
   - **Privacy Monitoring**: Real-time privacy compliance tracking per `data-governance.md`
   - **Compliance Integration**: APP compliance reporting for LLM interactions

**Documentation Updates:**
- Document routing decision logic with examples
- Create monitoring and analytics usage guidelines
- **Privacy Documentation**: Privacy monitoring and incident response procedures
- **Compliance Integration**: Reference `data-governance.md` reporting framework

### Phase 4: Optimization & Documentation (ongoing)
**Goal**: Continuous improvement and comprehensive documentation

**Components:**
1. **Feedback Loop Enhancement**
   - Automated log analysis for user satisfaction patterns
   - Response quality improvement based on usage data
   - Prompt optimization using real-world feedback
   - Example improvement cycles and success stories

2. **Performance Tuning**
   - Latency optimization with caching strategies
   - Cost management through intelligent routing
   - Quality consistency across template and LLM responses
   - Example performance improvements and benchmarks

3. **Comprehensive Documentation**
   - Update all affected `README.md` files
   - Create usage examples and best practices guides
   - Document integration points with existing codebase
   - Provide troubleshooting guides with common scenarios

## Technical Architecture Details

### Conservative Routing Strategy
```
Query → Enhanced Classifier → Privacy Check → Routing Decision → Handler → Response → Post-Processing

Routing Decision Logic:
1. **Privacy Validation**: PII detection and sanitisation (mandatory first step)
2. High confidence template match (>0.85) → Template Handler
3. Schema-related conversational query → LLM Handler (schema-only context)
4. Novel/complex pattern not in templates → LLM Handler  
5. Simple greetings/thanks → Template Handler
6. LLM failure/timeout → Template Handler (fallback)
7. **Cross-border Compliance**: Schema-only transmission validation before Gemini API
8. Unknown/low confidence → Template Handler (conservative default)
```

### LLM Integration Points
1. **Primary**: Conversational Handler (`src/rag/core/conversational/`)
2. **Secondary**: Query Classification (`src/rag/core/routing/query_classifier.py`)
3. **Supporting**: Schema Provider (`src/rag/core/llm/schema_provider.py`)
4. **Monitoring**: Feedback System (`src/rag/core/llm/monitoring/`)
5. **Privacy Compliance**: Integration with existing privacy controls (`src/rag/core/privacy/`)

### Privacy & Compliance Integration (per `data-governance.md`)
**Multi-layer Privacy Controls for LLM:**
- **Layer 1**: Conversational query PII scanning before LLM processing
- **Layer 2**: Schema-only context transmission (zero personal data to Gemini)
- **Layer 3**: Response sanitisation and Australian English post-processing
- **Layer 4**: Privacy-safe audit logging of LLM interactions

**APP Compliance Measures:**
- **APP 6 (Use/Disclosure)**: Schema-only transmission ensures no personal data disclosure
- **APP 8 (Cross-border)**: Explicit schema-only validation before Gemini API calls
- **APP 11 (Security)**: Encrypted transmission and privacy-safe error handling
- **APP 12 (Access)**: Complete audit trail of LLM interactions with PII anonymisation

### Schema Context Integration
**Data Source**: `src/csv/data-dictionary.json`
**Processing**: Rich context generation with examples
**Privacy Compliance**: Schema-only transmission (no personal data per `data-governance.md`)
**Caching**: Pre-computed schema descriptions for performance
**Updates**: Manual refresh with easy upgrade path

### Australian English Implementation
- **Spelling**: Post-processing for Australian spellings (colour, centre, analyse)
- **Tone**: Professional and helpful, neutral expressions
- **Consistency**: Ensure template and LLM responses feel cohesive
- **Examples**: "analyse" not "analyze", "centre" not "center"

### Success Criteria & Metrics
- **Performance**: 95% of responses under 2 seconds
- **Quality**: Maintained or improved user satisfaction via log analysis
- **Reliability**: 99.9% effective response rate with fallbacks
- **Cost**: Reasonable Gemini API usage within existing budget
- **Consistency**: Seamless experience between template and LLM responses
- **Australian Context**: Proper spelling and neutral professional tone
- **Privacy Compliance**: 100% APP compliance per `data-governance.md` requirements
- **Cross-border Security**: Zero personal data transmitted to external LLM APIs

### Example Usage Scenarios

#### Scenario 1: Simple Greeting (Template Route)
```
User: "Hello, how are you?"
Route: Template Handler (high confidence match)
Response: "Hello! I'm working well, thank you for asking. I'm here to help you analyse survey and training data. How can I assist you today?"
```

#### Scenario 2: Schema Question (LLM Route with Privacy Controls)
```
User: "What kind of training data do you have and how is it structured?"
Privacy Check: PII scanning (none detected)
Route: LLM Handler (schema-related conversational query)
Context: Schema-only from data-dictionary.json (no personal data)
Cross-border Validation: Schema-only transmission approved
Response: Gemini-generated response about data structure with Australian spelling
Audit: Privacy-safe logging of interaction
```

#### Scenario 3: Novel Query (LLM Route)
```
User: "I'm new to data analysis. Can you help me understand how to approach survey data interpretation in the Australian public service context?"
Route: LLM Handler (complex, educational query not in templates)
Response: Comprehensive, contextual guidance with Australian public service focus
```

#### Scenario 4: Privacy Violation Prevention
```
User: "Can you tell me about John Smith's training feedback?"
Privacy Check: PII detected (personal name)
Route: Automatic privacy-safe template response
Response: "I can help you analyse training feedback trends without referencing specific individuals. Try asking about general feedback themes or satisfaction levels."
Audit: Privacy incident logged, PII anonymised
```

#### Scenario 5: LLM Failure (Fallback)
```
User: Any query → LLM fails/times out
Route: Automatic fallback to Template Handler
Response: Template response with suggestion to try again
Log: LLM failure recorded for monitoring, privacy-safe error logging
```

## Implementation Roadmap

### Pre-Implementation Setup
- [ ] Review existing Gemini integration in text-to-SQL module
- [ ] Analyze `src/csv/data-dictionary.json` structure for schema context
- [ ] **Privacy Review**: Study existing privacy controls in `src/rag/core/privacy/`
- [ ] **Compliance Alignment**: Review `data-governance.md` requirements for LLM integration
- [ ] Document current conversational handler patterns for comparison
- [ ] Set up development branch for LLM integration

### Phase 1: Foundation Layer (Week 1-2)
**Core Development:**
- [ ] Create `src/rag/core/llm/` directory structure with README.md
- [ ] **Privacy Integration**: Extend existing PII detection for LLM queries
- [ ] **Cross-border Controls**: Implement schema-only transmission validation
- [ ] Implement `gemini_client.py` with comprehensive examples
- [ ] Build `schema_provider.py` using data-dictionary.json
- [ ] Create prompt templates with Australian English guidelines
- [ ] Implement response post-processing for Australian spelling
- [ ] Update query classifier with LLM fallback capability
- [ ] Build hybrid conversational handler with routing logic
- [ ] **Privacy Testing**: Create comprehensive test cases with example scenarios

**Documentation:**
- [ ] Create `src/rag/core/llm/README.md` with architecture overview
- [ ] Update `src/rag/core/README.md` to include LLM integration
- [ ] Update `src/rag/core/conversational/README.md` with hybrid approach
- [ ] **Privacy Documentation**: Reference `data-governance.md` compliance requirements
- [ ] Document integration points and dependencies

### Phase 2: Schema Intelligence (Week 3)
**Schema Enhancement:**
- [ ] Build rich schema context from data-dictionary.json
- [ ] **Privacy Compliance**: Ensure schema-only context (no personal data)
- [ ] Create example query patterns for schema understanding
- [ ] Implement schema caching with manual refresh
- [ ] Build prompt engineering framework with examples

**Testing & Validation:**
- [ ] Create `src/rag/tests/llm/` directory with comprehensive tests
- [ ] **Privacy Testing**: Implement PII detection and cross-border compliance tests
- [ ] Implement template vs. LLM response comparison
- [ ] Build Australian English validation tests
- [ ] Create schema accuracy test cases

**Documentation:**
- [ ] Create prompt engineering guidelines with examples
- [ ] Document schema integration approach
- [ ] Update testing documentation with LLM-specific cases
- [ ] **Privacy Documentation**: Document privacy control testing per `data-governance.md`

### Phase 3: Intelligent Routing (Week 4)
**Routing Optimization:**
- [ ] Implement conservative routing strategy
- [ ] **Privacy Integration**: Mandatory privacy validation in routing pipeline
- [ ] Build performance monitoring capabilities
- [ ] Create log-based feedback analysis system
- [ ] Implement A/B testing framework for gradual adoption

**Monitoring:**
- [ ] Create monitoring dashboard for LLM performance
- [ ] Implement cost tracking for Gemini API usage
- [ ] Build quality assessment metrics
- [ ] Create automated log analysis tools
- [ ] **Privacy Monitoring**: Real-time privacy compliance tracking per `data-governance.md`

**Documentation:**
- [ ] Document routing decision logic with examples
- [ ] Create monitoring and analytics usage guides
- [ ] Update troubleshooting documentation
- [ ] **Privacy Documentation**: Privacy monitoring and incident response procedures per `data-governance.md`

### Phase 4: Optimization (Ongoing)
**Continuous Improvement:**
- [ ] Implement automated feedback analysis
- [ ] Optimize prompts based on real-world usage
- [ ] Fine-tune routing thresholds
- [ ] Monitor and improve Australian English consistency
- [ ] **Privacy Optimization**: Continuous privacy control effectiveness measurement

**Documentation Finalization:**
- [ ] Update all affected README.md files
- [ ] Create comprehensive usage examples
- [ ] Document best practices and common patterns
- [ ] Create troubleshooting guides with solutions
- [ ] **Privacy Documentation**: Complete privacy integration guide referencing `data-governance.md`

### Key Dependencies & Context
**Existing Codebase Integration:**
- `src/rag/core/conversational/handler.py` - Current template system (preserve)
- `src/rag/core/routing/query_classifier.py` - Enhance with LLM capabilities
- `src/csv/data-dictionary.json` - Schema source for context generation
- `src/rag/core/privacy/` - Existing privacy controls to extend for LLM usage
- `documentations/data-governance.md` - Privacy and compliance framework reference
- Existing Gemini configuration from text-to-SQL integration

**New Directory Structure:**
```
src/rag/core/llm/
├── README.md
├── __init__.py
├── gemini_client.py
├── schema_provider.py
├── prompt_templates.py
├── response_processor.py
├── privacy/
│   ├── __init__.py
│   ├── llm_pii_detector.py
│   └── cross_border_validator.py
├── prompts/
│   ├── README.md
│   ├── system_prompts.py
│   ├── schema_prompts.py
│   ├── australian_context.py
│   └── privacy_prompts.py
└── monitoring/
    ├── README.md
    ├── performance_tracker.py
    ├── quality_assessor.py
    ├── log_analyzer.py
    ├── privacy_monitor.py
    └── compliance_reporter.py

src/rag/tests/llm/
├── README.md
├── test_gemini_integration.py
├── test_hybrid_routing.py
├── test_australian_context.py
├── test_schema_awareness.py
├── test_privacy_compliance.py
└── test_cross_border_controls.py
```

### Risk Mitigation
- **LLM Failures**: Comprehensive fallback to existing template system
- **Performance Issues**: Conservative routing with template-first approach
- **Cost Overruns**: Monitoring and intelligent routing to optimize API usage
- **Quality Degradation**: A/B testing and gradual rollout with feedback analysis
- **Consistency Issues**: Post-processing and prompt engineering for Australian English
- **Privacy Violations**: Multi-layer PII detection and schema-only transmission per `data-governance.md`
- **Cross-border Compliance**: Explicit validation before any external API calls
- **Audit Trail Gaps**: Privacy-safe logging integration with existing audit framework

### Success Validation
- **Technical**: All tests pass, performance metrics met
- **User Experience**: Log analysis shows maintained or improved satisfaction
- **Integration**: Seamless operation with existing RAG system
- **Documentation**: Comprehensive guides enable easy maintenance and upgrades

---

*Planning document to be updated based on discussion and decisions*