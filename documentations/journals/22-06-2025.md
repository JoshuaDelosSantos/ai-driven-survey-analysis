# Journal Entry - 22 June 2025

**Focus:** Phase 3 Task 3.1 - LangGraph Agent Development (ASYNC CORE) Implementation Plan

## Phase 3 Task 3.1: LangGraph Agent Development Implementation Plan

### Overview
Implement the core async LangGraph agent (`src/rag/core/agent.py`) as the central intelligence orchestrator that routes queries between SQL and vector search tools, with comprehensive error handling and graceful degradation.

### Implementation Strategy

#### 1. Dependency Management
- Add `langgraph>=0.0.40` to requirements.txt
- LangGraph provides state graph orchestration for complex workflow management

#### 2. Tool Integration Approach
- **Reuse existing tools**: Leverage `AsyncSQLTool` and `VectorSearchTool` (already async-ready and tested)
- **Create thin LangGraph node wrappers**: Maintains separation of concerns and tool independence
- **Benefits**: Preserves existing test coverage, reduces complexity, enables independent tool evolution

#### 3. State Schema Design
```python
class AgentState(TypedDict):
    # Input
    query: str
    session_id: str
    
    # Classification
    classification: Optional[str]  # "SQL", "VECTOR", "HYBRID", "CLARIFICATION_NEEDED"
    confidence: Optional[str]      # "HIGH", "MEDIUM", "LOW"
    classification_reasoning: Optional[str]
    
    # Tool Results
    sql_result: Optional[Dict[str, Any]]
    vector_result: Optional[Dict[str, Any]]
    
    # Synthesis
    final_answer: Optional[str]
    sources: Optional[List[str]]
    
    # Error Handling & Flow Control
    error: Optional[str]
    retry_count: int
    requires_clarification: bool
    user_feedback: Optional[str]
    
    # Metadata
    processing_time: Optional[float]
    tools_used: List[str]
```

#### 4. Error Handling Strategy
- **Classification fallbacks**: LLM → Rule-based → Clarification
- **Tool failures**: Retry with exponential backoff → Graceful degradation
- **Comprehensive logging**: All errors logged with PII anonymization
- **User-friendly messaging**: Technical errors converted to helpful guidance

### Detailed Implementation Phases

#### Phase 3.1.1: Core Infrastructure Setup

**File Updates:**
- `requirements.txt`: Add `langgraph>=0.0.40`
- `src/rag/core/agent.py`: Create main agent class with async initialization

**Core Components:**
- Define `AgentState` TypedDict with comprehensive state management
- Create `RAGAgent` class with async initialization patterns
- Implement basic graph structure with placeholder nodes
- Establish error handling foundation

#### Phase 3.1.2: Query Classification System

**File: `src/rag/core/routing/query_classifier.py`**

**Multi-Stage Classification Logic:**
1. **Rule-based pre-filter**: Fast regex patterns for obvious queries
   - SQL indicators: "count", "how many", "average", "percentage", "breakdown by"
   - Vector indicators: "what did people say", "feedback about", "experiences with"
   - Hybrid indicators: "analyze satisfaction", "compare feedback across"

2. **LLM-based classification**: Structured prompt with confidence scoring
   - Primary classification prompt from architecture document
   - Confidence scoring: HIGH (0.8-1.0), MEDIUM (0.5-0.79), LOW (0.0-0.49)
   - Classification categories: SQL, VECTOR, HYBRID, CLARIFICATION_NEEDED

3. **Fallback mechanisms**:
   - LLM failure → Rule-based fallback
   - Complete failure → Route to clarification

**Implementation Requirements:**
- Async methods throughout
- PII anonymization before LLM processing
- Comprehensive error handling with fallbacks
- Structured logging for classification decisions

#### Phase 3.1.3: LangGraph Node Implementation

**Core Nodes Structure:**

**1. `classify_query_node`**
- Integrates query_classifier multi-stage logic
- Updates state with classification and confidence
- Handles classification errors gracefully

**2. `sql_tool_node`**
- Wraps existing `AsyncSQLTool`
- Maintains tool independence through wrapper pattern
- Error handling with retry logic and graceful degradation

**3. `vector_search_tool_node`**
- Wraps existing `VectorSearchTool`
- Supports metadata filtering capabilities
- Handles embedding service failures with fallbacks

**4. `synthesis_node`**
- Combines results from multiple sources
- Context aggregation and answer formatting
- Source attribution and transparency

**5. `clarification_node`**
- Handles ambiguous queries requiring user input
- Presents structured options (A/B/C format from architecture)
- Manages clarification flow and user response processing

**6. `error_handling_node`**
- Centralized error management and recovery
- Graceful degradation strategies
- User-friendly error messaging

**Node Design Pattern:**
```python
async def sql_tool_node(state: AgentState) -> AgentState:
    """Wrapper node for existing AsyncSQLTool."""
    try:
        sql_tool = AsyncSQLTool(llm=get_llm())
        await sql_tool.initialize()
        result = await sql_tool.process_query(state["query"])
        return {
            **state,
            "sql_result": result,
            "tools_used": state["tools_used"] + ["sql"],
            "error": None
        }
    except Exception as e:
        return {
            **state,
            "error": f"SQL processing failed: {str(e)}",
            "tools_used": state["tools_used"] + ["sql_failed"]
        }
```

#### Phase 3.1.4: Graph Orchestration & Routing Logic

**Graph Structure:**
```
START → classify_query_node → conditional_routing
                                    ↓
     ┌─────────────────────────────────────────────┐
     ↓                    ↓                        ↓
sql_tool_node    vector_search_tool_node    clarification_node
     ↓                    ↓                        ↓
     └→ synthesis_node ←──┘                   [wait for user]
            ↓                                      ↓
        END ←─────── error_handling_node ←────────┘
```

**Conditional Routing Implementation:**
- HIGH confidence + SQL → sql_tool_node
- HIGH confidence + VECTOR → vector_search_tool_node  
- HIGH confidence + HYBRID → both tools in parallel → synthesis_node
- LOW confidence or CLARIFICATION_NEEDED → clarification_node
- Any node errors → error_handling_node

**Graph Construction:**
- Use LangGraph StateGraph for async node orchestration
- Implement conditional edges based on state classification
- Support parallel execution for hybrid queries
- Comprehensive error routing from all nodes

#### Phase 3.1.5: Answer Synthesis System

**File: `src/rag/core/synthesis/answer_generator.py`**

**Synthesis Strategies:**
- **SQL-only results**: Format tables with statistical insights and context
- **Vector-only results**: Summarize themes with representative quotes and sentiment analysis
- **Hybrid results**: Combine statistical context with qualitative insights for comprehensive answers
- **Error states**: Provide helpful guidance and alternative query suggestions

**Core Components:**
- Context aggregation from multiple tool sources
- Template-based answer formatting with structured output
- Source attribution for transparency and audit compliance
- Integration points for early feedback collection system

**Answer Quality Features:**
- Relevance scoring and result ranking
- Source diversity and representativeness
- Clear distinction between quantitative and qualitative insights
- Privacy-safe result presentation with PII protection

#### Phase 3.1.6: Terminal Application Integration

**File: `src/rag/interfaces/terminal_app.py`**

**Integration Requirements:**
- Replace existing query processing with RAGAgent as primary entry point
- Maintain existing async patterns and session management
- Add feedback collection after each response (thumbs up/down rating)
- Implement graceful error display with user-friendly messaging

**Integration Pattern:**
```python
async def process_query(self, user_query: str) -> str:
    """Process query through LangGraph agent."""
    initial_state = {
        "query": user_query,
        "session_id": self.session_id,
        "retry_count": 0,
        "tools_used": [],
        "requires_clarification": False
    }
    
    final_state = await self.agent.ainvoke(initial_state)
    return self._format_response(final_state)
```

**Features to Implement:**
- Seamless transition from current SQL-only processing
- Interactive clarification handling for ambiguous queries
- Progress indicators for long-running operations
- Enhanced error messaging with recovery suggestions

#### Phase 3.1.7: Privacy & Security Integration

**PII Protection Requirements:**
- All user queries automatically anonymized before LLM processing using existing PII detection
- Error messages sanitized before user display to prevent information leakage
- Comprehensive audit logging with privacy protection throughout the agent workflow
- Integration with existing Australian PII detection system

**Security Measures:**
- Maintain read-only database constraints across all agent operations
- Input validation for all user queries and state transitions
- Rate limiting considerations for LLM API calls
- Secure credential handling consistent with existing patterns

**Compliance Features:**
- Australian Privacy Principles (APP) compliance maintained throughout workflow
- Data sovereignty controls for cross-border LLM API usage
- Complete audit trail with anonymized query logging
- Error handling that prevents sensitive data exposure

### File Structure & Dependencies

#### New Files to Create:
```
src/rag/core/
├── agent.py                     # Main LangGraph agent orchestrator
├── routing/
│   ├── __init__.py
│   └── query_classifier.py     # Multi-stage classification system
└── synthesis/
    ├── __init__.py
    └── answer_generator.py      # Context aggregation & formatting
```

#### Files to Modify:
```
requirements.txt                 # Add langgraph dependency
src/rag/interfaces/terminal_app.py  # Agent integration and feedback collection
src/rag/config/settings.py      # Agent configuration options and thresholds
```

#### Dependencies on Existing Components:
- `AsyncSQLTool` (src/rag/core/text_to_sql/sql_tool.py) - SQL processing
- `VectorSearchTool` (src/rag/core/vector_search/vector_search_tool.py) - Semantic search
- `PIIDetector` (src/rag/core/privacy/pii_detector.py) - Privacy protection
- LLM utilities (src/rag/utils/llm_utils.py) - Multi-provider LLM access
- Logging utilities (src/rag/utils/logging_utils.py) - Privacy-safe logging

### Quality Assurance Strategy

#### Error Handling Priorities:
1. **Classification failures**: LLM classification → Rule-based fallback → User clarification
2. **Tool failures**: Retry with exponential backoff → Graceful degradation with user notification
3. **Network issues**: Connection retry → Timeout handling → Offline mode suggestions
4. **Unexpected errors**: Safe error messages → Comprehensive audit logging → Recovery guidance

#### Maintainability Features:
- **Modular design**: Each node independently testable and replaceable
- **Configuration-driven**: Prompts, thresholds, and routing rules externalized
- **Comprehensive logging**: Full audit trail for debugging and compliance
- **Type safety**: TypedDict for state management with clear contracts

#### Upgrade Path Considerations:
- **Tool interface abstraction**: Easy to swap underlying tool implementations
- **Graph flexibility**: Simple to add new nodes or modify routing logic
- **State evolution**: AgentState can be extended without breaking existing functionality
- **Provider agnostic**: LLM provider switching supported through existing utilities

### Success Criteria

#### Functional Requirements:
1. **Query routing accuracy** ≥ 90% for clear SQL/Vector queries using classification system
2. **Error recovery**: All error states handled gracefully with user-friendly messaging
3. **Response generation**: Coherent answers from single and multiple tool sources
4. **Privacy compliance**: Zero PII leakage in processing, storage, or outputs

#### Performance Targets:
1. **End-to-end response time** < 15 seconds for hybrid queries requiring both tools
2. **Classification speed** < 1 second for rule-based, < 3 seconds for LLM-based classification
3. **Memory efficiency**: No memory leaks in long-running terminal sessions
4. **Async responsiveness**: Non-blocking throughout entire pipeline with proper concurrency

#### Integration Requirements:
1. **Backward compatibility**: Existing tools continue to work independently of agent
2. **Terminal integration**: Seamless replacement of current query processing workflow
3. **Configuration compatibility**: Uses existing settings and environment variables
4. **Logging consistency**: Integrates with existing audit and privacy logging systems

### Implementation Notes

#### Critical Design Decisions:
- **State-first approach**: All workflow state managed through TypedDict for clarity
- **Wrapper pattern**: Preserve existing tool interfaces while adding LangGraph integration
- **Error-first design**: Every node must handle and propagate errors appropriately
- **Privacy-by-design**: PII protection integrated at every processing step

#### Key Technical Patterns:
- **Async throughout**: All nodes, tools, and utilities support async/await
- **Immutable state updates**: State transitions create new state objects
- **Structured logging**: Consistent log format across all agent operations
- **Graceful degradation**: Partial functionality maintained during component failures

This implementation plan provides the foundation for a robust, maintainable, and upgradeable LangGraph agent that serves as the central intelligence for the RAG system while maintaining all existing privacy, security, and performance requirements.