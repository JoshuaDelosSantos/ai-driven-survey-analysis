# Focus
1. Core Topics Identified for Research
- 1.1 Initial topics:
  - Sentiment Analysis
  - Retrieval-Augmented Generation (RAG)
  - Database technologies
  - Data Privacy
  - LLM selection
- 1.2 Expanded topics (from today's discussion and the detailed research prompt we curated):
  - Sentiment Analysis Deep Dive: Fundamentals (rule-based, ML, hybrid), specific models/tools (OpenAI API, local options like RoBERTa), survey-specific preprocessing, handling nuances (sarcasm, Aspect-Based Sentiment Analysis), RAG integration, evaluation metrics, and ethical considerations.
  - Embedding strategies
  - Chunking and indexing for RAG 
  - Data normalization and schema design
  - File ingestion automation (cloud-hosted workflows, specifically Google Sheets API vs. Drive API for Qualtrics data)
  - Stakeholder-facing presentation design
  - API usage constraints (e.g. OpenAI rate limits, privacy implications)

2. Project Scope and Learning Outcomes
- 2.1 Refined my initial learning outcomes to be more flexible and skill-oriented, based on feedback from my subject coordinator.
- 2.2 Aligned outcomes around broad capabilities such as applying modern AI techniques, stakeholder communication, and ethical considerations.
- 2.3 Re-centered the project goals around outcomes (skills and learning) rather than rigid outputs.

3. Technical Architecture & Workflow Design
- 3.1 Chose an MVP architecture using:
  - OpenAI API (for embeddings and generation)
  - PostgreSQL (relational DB for normalized storage)
  - Docker (to orchestrate modular services)
- 3.2 Original Workflow design:
  - Survey responses are collected via Qualtrics and saved to a cloud Excel file (e.g. Google Drive).
  - A Dockerized worker service will periodically fetch this file, transform it using ETL logic, and populate normalized database tables.
  - Free-text feedback will be cleaned, chunked, embedded using OpenAI, and enriched with sentiment scores.
  - RAG will then retrieve and summarize relevant responses in real-time for user queries via a front-end or API layer.
- 3.3 Decision for MVP1 - Manual DB Population:
  - To focus development, decided to skip live Google Sheet ingestion for MVP1 and manually populate the database with an initial 100 survey responses.
- 3.4 Sentiment Analysis Workflow (with manually populated DB):
  - The worker component will identify responses in the responses table needing processing.
  - It will perform text cleaning and chunking.
  - Embeddings will be generated for each chunk using the OpenAI Embeddings API.
  - Sentiment analysis will be performed on these chunks.
  - Results (chunk text, embedding, sentiment score) will be stored in the response_chunks table.
- 3.5 Refining Sentiment Analysis - Local RoBERTa:
  - The architecture now specifies that the worker "Runs local RoBERTa model for sentiment analysis".
  - The worker's Dockerfile will include transformers, torch, and the RoBERTa model files.
  - Detailed changes for asynchronous processing and inference are noted.

4. Practical Considerations and Design Nuances
- 4.1 Data ingestion (learnings for future iteration, post-MVP1):
  - Qualtrics updates a single file rather than creating new ones.
  - This requires a polling or scheduled retrieval approach (e.g., using the Google Sheets API).
- 4.2 ETL approach:
  - Implement a deduplication or upsert strategy based on a unique response_id or submitted_at field.
- 4.3 Privacy and constraints:
  - Research data privacy concerns (e.g., GDPR) and adjust processing to maintain compliance.

5. Mindset and Reflection
- 5.1 Moved from a tool-centric mindset to an outcome-driven one.
- 5.2 Gained confidence in integrating cloud-stored data into a local processing pipeline.
- 5.3 Identified communication and public speaking as skill gaps.
- 5.4 Embraced challenges in mapping high-level ideas to detailed architecture.