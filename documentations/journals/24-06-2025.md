# Journal Entry - 24 June 2025

**Focus:** Phase 3 Task 3.2 - Resilient Query Classification Component Implementation Plan

## Project Summary: Phase 3.2 Enhanced Query Classification

**Overview:**
* Plan to enhance the existing query classification system with improved resilience, accuracy, and Australian Public Service domain-specific optimisations.
* Focus on upgrading the current `query_classifier.py` with sophisticated fallback mechanisms and confidence calibration.

---

## Phase 3 Task 3.2: Enhanced Query Classification Implementation Plan

### Current State Analysis

**Existing Implementation Review:**
* âœ… Basic `QueryClassifier` in `src/rag/core/routing/query_classifier.py` with multi-stage processing
* âœ… Rule-based pre-filtering with regex patterns for SQL, VECTOR, and HYBRID categories
* âœ… LLM-based classification with confidence scoring 
* âœ… Australian PII detection integration throughout classification pipeline
* âœ… Integration with LangGraph agent via `_classify_query_node` in `agent.py`

**Current Limitations Identified:**
* Limited rule-based patterns focused on general keywords rather than Australian Public Service specific terminology
* Basic confidence calibration without adaptive thresholds
* Minimal fallback mechanisms beyond simple error handling
* No clarification flow integration for ambiguous queries
* Limited performance monitoring and accuracy tracking

### Enhancement Objectives

**Primary Goals:**
1. **Improve Classification Accuracy**: Enhance rule-based patterns with Australian Public Service domain knowledge
2. **Strengthen Resilience**: Implement sophisticated fallback mechanisms with exponential backoff
3. **Optimise Confidence Calibration**: Develop adaptive confidence thresholds based on query complexity
4. **Integrate Clarification Flow**: Seamlessly handle ambiguous queries within LangGraph agent nodes
5. **Maintain Simplicity**: Keep MVP focus while building foundation for future enhancements

---

## Detailed Implementation Strategy

### 1. Enhanced Rule-Based Pre-Filtering (`query_classifier.py`)

**Objective**: Expand rule-based patterns to improve first-pass accuracy for Australian Public Service queries

**Implementation Plan:**

#### 1.1 Australian Public Service Domain Patterns
```python
# Enhanced SQL patterns for APS context
_enhanced_sql_patterns = [
    # Existing patterns (preserved)
    ...existing patterns...
    
    # New APS-specific patterns
    r'\b(?:executive level|level [1-6]|EL[12]|APS [1-6])\b.*(?:completion|attendance|performance)',
    r'\b(?:agency|department|portfolio).*(?:breakdown|comparison|statistics)',
    r'\b(?:learning pathway|professional development|capability framework).*(?:metrics|data)',
    r'\b(?:mandatory training|compliance training).*(?:rates|numbers|tracking)',
    r'\b(?:face-to-face|virtual|blended).*(?:delivery|attendance|completion)',
    r'\b(?:cost per|budget|resource allocation).*(?:training|learning)',
    r'\b(?:quarterly|annual|yearly).*(?:training|learning|development).*(?:report|summary)'
]

# Enhanced VECTOR patterns for APS feedback
_enhanced_vector_patterns = [
    # Existing patterns (preserved)
    ...existing patterns...
    
    # New APS-specific patterns
    r'\b(?:participant|delegate|attendee).*(?:experience|reflection|view)',
    r'\b(?:training quality|course quality|learning experience).*(?:feedback|assessment)',
    r'\b(?:facilitator|presenter|instructor).*(?:effectiveness|skill|performance)',
    r'\b(?:venue|location|facilities).*(?:issues|problems|concerns)',
    r'\b(?:accessibility|inclusion|diversity).*(?:feedback|experience)',
    r'\b(?:technical issues|platform problems|system difficulties)',
    r'\b(?:relevance to role|workplace application|practical use)'
]

# Enhanced HYBRID patterns for comprehensive analysis
_enhanced_hybrid_patterns = [
    # Existing patterns (preserved)
    ...existing patterns...
    
    # New APS-specific patterns
    r'\b(?:analyse|analyze).*(?:satisfaction|effectiveness).*(?:across|by|between)',
    r'\b(?:training ROI|return on investment|cost-benefit).*(?:analysis|evaluation)',
    r'\b(?:performance impact|capability improvement|skill development).*(?:measurement|assessment)',
    r'\b(?:stakeholder satisfaction|user experience).*(?:metrics|analysis)',
    r'\b(?:trend analysis|pattern identification|insight generation)',
    r'\b(?:comprehensive|holistic|integrated).*(?:evaluation|assessment|review)'
]
```

#### 1.2 Pattern Weighting System
```python
# Implement pattern importance weighting
_pattern_weights = {
    "SQL": {
        "high_confidence": [r'\b(?:count|how many|number of)\b', r'\b(?:percentage|percent)\b'],
        "medium_confidence": [r'\b(?:breakdown by|group by)\b', r'\b(?:statistics|stats)\b'],
        "low_confidence": [r'\b(?:compare|comparison)\b']
    },
    "VECTOR": {
        "high_confidence": [r'\b(?:what did.*say|feedback about)\b', r'\b(?:comments|opinions)\b'],
        "medium_confidence": [r'\b(?:experiences with|satisfaction)\b'],
        "low_confidence": [r'\b(?:thoughts|feelings)\b']
    },
    "HYBRID": {
        "high_confidence": [r'\b(?:analyze satisfaction|comprehensive analysis)\b'],
        "medium_confidence": [r'\b(?:trends in|patterns in)\b'],
        "low_confidence": [r'\b(?:both.*and|detailed analysis)\b']
    }
}
```

### 2. Sophisticated Fallback Mechanisms

**Objective**: Implement multi-tier fallback system with exponential backoff and graceful degradation

**Implementation Plan:**

#### 2.1 Enhanced `_llm_based_classification` Method
```python
async def _llm_based_classification_with_fallback(self, query: str) -> ClassificationResult:
    """
    Enhanced LLM classification with sophisticated fallback mechanisms.
    
    Fallback hierarchy:
    1. Primary LLM classification (3 retries with exponential backoff)
    2. Simplified LLM prompt classification (2 retries)
    3. Enhanced rule-based classification
    4. Default classification with CLARIFICATION_NEEDED
    """
    
    # Tier 1: Primary LLM classification with retries
    for attempt in range(3):
        try:
            result = await self._primary_llm_classification(query)
            if result.confidence in ["HIGH", "MEDIUM"]:
                return result
        except Exception as e:
            logger.warning(f"Primary LLM classification attempt {attempt + 1} failed: {e}")
            if attempt < 2:  # Exponential backoff
                await asyncio.sleep(2 ** attempt)
    
    # Tier 2: Simplified LLM prompt
    try:
        return await self._simplified_llm_classification(query)
    except Exception as e:
        logger.warning(f"Simplified LLM classification failed: {e}")
    
    # Tier 3: Enhanced rule-based fallback
    enhanced_rule_result = self._enhanced_rule_based_classification(query)
    if enhanced_rule_result:
        return enhanced_rule_result
    
    # Tier 4: Default fallback
    return self._default_classification_fallback(query)
```

#### 2.2 Confidence Calibration System
```python
class ConfidenceCalibrator:
    """
    Adaptive confidence calibration based on query complexity and historical accuracy.
    """
    
    def __init__(self):
        self._accuracy_history = {"SQL": [], "VECTOR": [], "HYBRID": []}
        self._complexity_factors = {
            "keyword_density": 0.2,
            "query_length": 0.1,
            "domain_specificity": 0.3,
            "ambiguity_markers": 0.4
        }
    
    def calibrate_confidence(self, 
                           raw_confidence: float, 
                           classification: str, 
                           query: str) -> ConfidenceLevel:
        """
        Adjust confidence based on query complexity and historical performance.
        """
        complexity_score = self._calculate_complexity(query)
        historical_accuracy = self._get_historical_accuracy(classification)
        
        # Adjust confidence based on complexity and history
        adjusted_confidence = raw_confidence * (1 - complexity_score * 0.3) * historical_accuracy
        
        if adjusted_confidence >= 0.8:
            return "HIGH"
        elif adjusted_confidence >= 0.5:
            return "MEDIUM"
        else:
            return "LOW"
```

### 3. Clarification Flow Integration

**Objective**: Seamlessly integrate clarification handling within existing LangGraph agent architecture

**Implementation Plan:**

#### 3.1 Enhanced Agent Node Integration
```python
# Modify existing _classify_query_node in agent.py
async def _classify_query_node(self, state: AgentState) -> AgentState:
    """
    Enhanced query classification with clarification flow integration.
    """
    try:
        classification_result = await self._query_classifier.classify_query(
            query=state["query"],
            session_id=state["session_id"]
        )
        
        # Handle low confidence classifications
        if classification_result.confidence == "LOW":
            return {
                **state,
                "classification": "CLARIFICATION_NEEDED",
                "clarification_options": self._generate_clarification_options(
                    state["query"], 
                    classification_result
                ),
                "original_classification": classification_result,
                "tools_used": state["tools_used"] + ["classifier_clarification"]
            }
        
        # Proceed with confident classification
        return {
            **state,
            "classification": classification_result.classification,
            "confidence": classification_result.confidence,
            "classification_reasoning": classification_result.reasoning,
            "tools_used": state["tools_used"] + ["classifier"]
        }
        
    except Exception as e:
        # Enhanced error handling with user-friendly messaging
        return self._handle_classification_error(state, e)
```

#### 3.2 Clarification Options Generation
```python
def _generate_clarification_options(self, query: str, classification_result: ClassificationResult) -> Dict[str, str]:
    """
    Generate contextual clarification options based on query content.
    """
    options = {
        "A": "ðŸ“Š Statistical summary or numerical breakdown (counts, percentages, trends)",
        "B": "ðŸ’¬ Specific feedback, comments, or user experiences",
        "C": "ðŸ“ˆ Combined analysis with both statistics and qualitative insights"
    }
    
    # Contextualise options based on query content
    if "satisfaction" in query.lower():
        options["A"] = "ðŸ“Š Satisfaction ratings and statistical analysis"
        options["B"] = "ðŸ’¬ Detailed satisfaction feedback and comments"
        options["C"] = "ðŸ“ˆ Complete satisfaction analysis with ratings and feedback"
    
    return options
```

### 4. Performance Monitoring and Accuracy Tracking

**Objective**: Implement lightweight monitoring system for classification performance

**Implementation Plan:**

#### 4.1 Classification Metrics Collection
```python
class ClassificationMetrics:
    """
    Lightweight metrics collection for classification performance monitoring.
    """
    
    def __init__(self):
        self._metrics = {
            "total_classifications": 0,
            "method_distribution": {"rule_based": 0, "llm_based": 0, "fallback": 0},
            "confidence_distribution": {"HIGH": 0, "MEDIUM": 0, "LOW": 0},
            "classification_times": [],
            "clarification_rate": 0.0
        }
    
    def record_classification(self, result: ClassificationResult):
        """Record classification result for performance analysis."""
        self._metrics["total_classifications"] += 1
        self._metrics["method_distribution"][result.method_used] += 1
        self._metrics["confidence_distribution"][result.confidence] += 1
        self._metrics["classification_times"].append(result.processing_time)
        
        if result.classification == "CLARIFICATION_NEEDED":
            self._metrics["clarification_rate"] = (
                self._metrics["clarification_rate"] * (self._metrics["total_classifications"] - 1) + 1
            ) / self._metrics["total_classifications"]
```

---

## Implementation Sequence

### Phase 1: Core Enhancement (Week 1)
1. **Enhance Rule-Based Patterns**: Implement Australian Public Service specific patterns
2. **Improve Confidence Calibration**: Add adaptive confidence thresholds
3. **Basic Fallback Mechanisms**: Implement multi-tier fallback system

### Phase 2: Integration & Resilience (Week 2)
1. **Agent Integration**: Enhance `_classify_query_node` with clarification flow
2. **Error Handling**: Implement sophisticated error recovery mechanisms
3. **Performance Monitoring**: Add basic metrics collection

### Phase 3: Testing & Validation (Week 3)
1. **Core Functionality Tests**: Test enhanced classification accuracy
2. **Fallback Mechanism Tests**: Validate error recovery scenarios
3. **Integration Tests**: Ensure seamless LangGraph agent integration

---

## Technical Implementation Details

### File Modifications Required

#### 1. `src/rag/core/routing/query_classifier.py`
**Enhancements:**
- Expand rule-based patterns with APS-specific terminology
- Implement sophisticated fallback mechanisms with exponential backoff
- Add confidence calibration based on query complexity
- Integrate lightweight performance monitoring

#### 2. `src/rag/core/agent.py`
**Modifications:**
- Enhance `_classify_query_node` with clarification flow handling
- Improve error handling with user-friendly messaging
- Add clarification options generation logic

#### 3. `src/rag/config/settings.py`
**Additions:**
- Configuration options for enhanced classification thresholds
- Fallback mechanism parameters
- Performance monitoring settings

### Dependencies and Imports

**Required Imports Analysis:**
```python
# For query_classifier.py enhancements
import asyncio
import time
import statistics
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, field

# For agent.py modifications
from ..routing.query_classifier import ClassificationResult
from typing import Dict, Any

# For performance monitoring
import json
from datetime import datetime
```

### Example Use Cases

#### Example 1: Enhanced Classification
```python
# Enhanced rule-based classification for APS queries
classifier = QueryClassifier()
await classifier.initialize()

# Test with Australian Public Service specific query
result = await classifier.classify_query(
    "How many Executive Level 1 participants completed mandatory training across all agencies this quarter?"
)
print(f"Classification: {result.classification}")  # Expected: SQL
print(f"Confidence: {result.confidence}")          # Expected: HIGH
print(f"Method: {result.method_used}")             # Expected: rule_based
```

#### Example 2: Fallback Mechanism
```python
# Test fallback mechanisms with simulated LLM failure
result = await classifier.classify_query(
    "Tell me about the training effectiveness"  # Ambiguous query
)
print(f"Classification: {result.classification}")  # Expected: CLARIFICATION_NEEDED
print(f"Confidence: {result.confidence}")          # Expected: LOW
print(f"Method: {result.method_used}")             # Expected: fallback
```

#### Example 3: Agent Integration
```python
# Test enhanced agent classification with clarification flow
agent = await create_rag_agent()
result = await agent.ainvoke({
    "query": "How satisfied are users with training?",  # Potentially ambiguous
    "session_id": "test_session"
})

if result.get("classification") == "CLARIFICATION_NEEDED":
    print("Clarification options:", result["clarification_options"])
```

---

## Future Enhancements (For Architecture Document)

### Advanced Features for Future Phases

#### 1. Machine Learning-Based Classification
- **Objective**: Implement supervised learning model trained on Australian Public Service queries
- **Implementation**: Fine-tuned BERT model for domain-specific classification
- **Benefits**: Improved accuracy for complex and novel query patterns

#### 2. Dynamic Pattern Learning
- **Objective**: Automatically identify and incorporate new classification patterns
- **Implementation**: Pattern mining from successful classification history
- **Benefits**: Continuous improvement without manual pattern updates

#### 3. Multi-Language Support
- **Objective**: Support queries in multiple languages relevant to Australian Public Service
- **Implementation**: Multi-language PII detection and classification
- **Benefits**: Broader accessibility for diverse user base

#### 4. Advanced Confidence Calibration
- **Objective**: Implement sophisticated confidence scoring using ensemble methods
- **Implementation**: Combine multiple classification signals with learned weights
- **Benefits**: More accurate confidence estimation for better routing decisions

#### 5. User Feedback Integration
- **Objective**: Incorporate user feedback to improve classification accuracy
- **Implementation**: Active learning system with user correction feedback
- **Benefits**: Continuous improvement based on real user interactions

---

## Quality Assurance & Testing Strategy

### Testing Approach (Minimal but Comprehensive)

#### 1. Core Functionality Tests
```python
# Test enhanced rule-based classification
async def test_enhanced_rule_based_classification():
    classifier = QueryClassifier()
    
    # Test APS-specific patterns
    test_cases = [
        ("How many EL1 staff completed training?", "SQL", "HIGH"),
        ("What feedback did participants give about virtual learning?", "VECTOR", "HIGH"),
        ("Analyze satisfaction trends across agencies with supporting comments", "HYBRID", "MEDIUM")
    ]
    
    for query, expected_classification, expected_confidence in test_cases:
        result = await classifier.classify_query(query)
        assert result.classification == expected_classification
        assert result.confidence == expected_confidence
```

#### 2. Fallback Mechanism Tests
```python
# Test fallback mechanisms
async def test_fallback_mechanisms():
    # Simulate LLM failure
    classifier = QueryClassifier(llm=None)  # Force fallback
    
    result = await classifier.classify_query("Complex ambiguous query")
    assert result.method_used == "fallback"
    assert result.confidence in ["LOW", "MEDIUM"]
```

#### 3. Integration Tests
```python
# Test agent integration
async def test_agent_integration():
    agent = await create_rag_agent()
    
    # Test clarification flow
    result = await agent.ainvoke({
        "query": "Tell me about training",  # Ambiguous
        "session_id": "test"
    })
    
    assert "clarification_options" in result
    assert len(result["clarification_options"]) == 3
```

---

## Summary

This implementation plan focuses on enhancing the existing query classification system with:

1. **Improved Accuracy**: Australian Public Service specific patterns and advanced confidence calibration
2. **Enhanced Resilience**: Multi-tier fallback mechanisms with exponential backoff
3. **Seamless Integration**: Clarification flow within existing LangGraph agent architecture
4. **Maintainable Design**: Modular enhancements that preserve existing functionality
5. **Future-Ready**: Foundation for advanced features while maintaining MVP simplicity

The plan prioritises accuracy and maintainability as requested, with minimal but effective testing to ensure reliability. The implementation will enhance the existing codebase without breaking changes, ensuring smooth integration with the current RAG system architecture.